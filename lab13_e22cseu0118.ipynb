{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachitt-t/AI-in-healthcare/blob/main/lab13_e22cseu0118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RACHIT TAYAL E22CSEU0118"
      ],
      "metadata": {
        "id": "RW2y3-v93Usa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install rdkit-pypi torch torchvision pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nvd-L0i3T52",
        "outputId": "6cdc46e2-db01-405a-b2fe-4ca54ccae1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement rdkit-pypi (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for rdkit-pypi\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjXozRyswq1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b14ef12-f434-49a0-9859-143d831be7af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.1\n",
            "Loading SMILES from: /content/test.txt\n",
            "Loaded 176075 SMILES from txt file\n",
            "Vocab size: 52\n",
            "SmilesRNN(\n",
            "  (embed): Embedding(52, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 512, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=512, out_features=52, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:15<00:00,  5.05it/s, loss=0.807]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 — loss: 0.8070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.77it/s, loss=0.568]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/8 — loss: 0.5683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.77it/s, loss=0.536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/8 — loss: 0.5360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.76it/s, loss=0.517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/8 — loss: 0.5172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.77it/s, loss=0.504]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/8 — loss: 0.5040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.76it/s, loss=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/8 — loss: 0.4938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.76it/s, loss=0.485]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/8 — loss: 0.4855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 687/687 [02:24<00:00,  4.77it/s, loss=0.478]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8 — loss: 0.4785\n",
            "Example Generated SMILES:\n",
            "Cc1csc(NC(=O)Cn2nnc3c(cnn3C)c2=O)n1test\n",
            "CCNC(=O)c1cccc(NC(=O)C(C)(C)C)c1Ctest\n",
            "O=C(Nc1ccc2c(c1)OCO2)c1c[nH]nc1-c1ccc(Cl)cc1test\n",
            "COc1ccc(NC(=O)c2sc(-n3cccc3)nc2C)cc1test\n",
            "CCCS(=O)(=O)N1CCC(C(=O)c2ccccc2C)CC1test\n",
            "CC1CCCCC1NC(=O)c1c[nH]nc1-c1ccccc1test\n",
            "COCCN(Cc1ccccc1)C(=O)Nc1ccccc1Ntest\n",
            "CCOC1CCN(C(=O)COc2cccc(Cl)c2C)CC1test\n",
            "COc1c(F)cc(NCC2CCCN(C(=O)C(C)C)C2)c(Cl)c1test\n",
            "CCOc1cccc2c1OCC(C(=O)Nc1ccc(C)c(F)c1)C2test\n"
          ]
        }
      ],
      "source": [
        "# Full end-to-end SMILES generative pipeline (PyTorch + RDKit)\n",
        "# Runs on Google Colab or local environment.\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 0) Install dependencies (Colab)\n",
        "# -------------------------\n",
        "!pip install rdkit torch torchvision pandas tqdm\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 1) Imports\n",
        "# -------------------------\n",
        "import re\n",
        "import random\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# RDKit\n",
        "from rdkit import Chem\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 2) Configuration & helper tokens\n",
        "# -------------------------\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "START_TOKEN = \"<s>\"\n",
        "END_TOKEN = \"</s>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 512\n",
        "NUM_LAYERS = 2\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3\n",
        "EPOCHS = 8\n",
        "MAX_SEQ_LEN = 120\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 3) Tokenizer (regex)\n",
        "# -------------------------\n",
        "SMILES_TOKENIZER_REGEX = re.compile(\n",
        "    r\"(\\%\\d{2}|Br|Cl|Si|Se|\\[[^\\]]+\\]|@@?|==|=|#|:|~|\\/|\\\\|\\(|\\)|\\.|\\+|\\-|\\d+|[A-Za-z])\"\n",
        ")\n",
        "\n",
        "def tokenize_smiles(smiles: str) -> List[str]:\n",
        "    tokens = SMILES_TOKENIZER_REGEX.findall(smiles)\n",
        "    return [t for t in tokens if t.strip()]\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# -------------------------\n",
        "# 4) Load dataset from TXT file (using fixed path)\n",
        "# -------------------------\n",
        "\n",
        "TXT_PATH = \"/content/test.txt\"   # your file path\n",
        "\n",
        "def load_txt_smiles(path):\n",
        "    smiles_list = []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            s = line.strip()\n",
        "            if len(s) == 0:\n",
        "                continue\n",
        "            if len(s) > MAX_SEQ_LEN - 2:\n",
        "                continue\n",
        "            smiles_list.append(s)\n",
        "    return smiles_list\n",
        "\n",
        "print(\"Loading SMILES from:\", TXT_PATH)\n",
        "smiles_all = load_txt_smiles(TXT_PATH)\n",
        "print(\"Loaded\", len(smiles_all), \"SMILES from txt file\")\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 5) Build vocabulary\n",
        "# -------------------------\n",
        "counter = Counter()\n",
        "for s in smiles_all:\n",
        "    counter.update(tokenize_smiles(s))\n",
        "\n",
        "tokens = sorted(counter.keys(), key=lambda x: (-counter[x], x))\n",
        "vocab = [PAD_TOKEN, START_TOKEN, END_TOKEN, UNK_TOKEN] + tokens\n",
        "\n",
        "token2idx = {t: i for i, t in enumerate(vocab)}\n",
        "idx2token = {i: t for t, i in token2idx.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 6) Encode + decode\n",
        "# -------------------------\n",
        "def encode(tokens: List[str], token2idx: dict, max_len: int):\n",
        "    seq = [token2idx[START_TOKEN]]\n",
        "    for t in tokens:\n",
        "        seq.append(token2idx.get(t, token2idx[UNK_TOKEN]))\n",
        "        if len(seq) >= max_len - 1:\n",
        "            break\n",
        "    seq.append(token2idx[END_TOKEN])\n",
        "    if len(seq) < max_len:\n",
        "        seq = seq + [token2idx[PAD_TOKEN]] * (max_len - len(seq))\n",
        "    return seq[:max_len]\n",
        "\n",
        "def decode(indices: List[int], idx2token: dict) -> str:\n",
        "    result = []\n",
        "    for idx in indices:\n",
        "        tok = idx2token[idx]\n",
        "        if tok == END_TOKEN:\n",
        "            break\n",
        "        if tok in (PAD_TOKEN, START_TOKEN):\n",
        "            continue\n",
        "        result.append(tok)\n",
        "    return \"\".join(result)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 7) PyTorch Dataset\n",
        "# -------------------------\n",
        "class SmilesDataset(Dataset):\n",
        "    def __init__(self, smiles_list, token2idx, max_len):\n",
        "        self.smiles = smiles_list\n",
        "        self.token2idx = token2idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.smiles[idx]\n",
        "        toks = tokenize_smiles(s)\n",
        "        seq = encode(toks, self.token2idx, self.max_len)\n",
        "        x = torch.tensor(seq[:-1], dtype=torch.long)  # input\n",
        "        y = torch.tensor(seq[1:], dtype=torch.long)   # next token target\n",
        "        return x, y\n",
        "\n",
        "dataset = SmilesDataset(smiles_all, token2idx, MAX_SEQ_LEN)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 8) Model (LSTM)\n",
        "# -------------------------\n",
        "class SmilesRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        emb = self.embed(x)\n",
        "        out, hidden = self.lstm(emb, hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hidden\n",
        "\n",
        "model = SmilesRNN(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    pad_idx=token2idx[PAD_TOKEN]\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2idx[PAD_TOKEN])\n",
        "\n",
        "print(model)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 9) Train model\n",
        "# -------------------------\n",
        "def train_one_epoch(model, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    pbr = tqdm(dataloader)\n",
        "    for x, y in pbr:\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits, _ = model(x)\n",
        "        loss = criterion(logits.reshape(-1, vocab_size), y.reshape(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        pbr.set_postfix(loss=total_loss/(pbr.n+1))\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    loss = train_one_epoch(model, dataloader)\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} \\u2014 loss: {loss:.4f}\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 10) Generate SMILES\n",
        "# -------------------------\n",
        "def sample_next_token(logits, temperature=1.0):\n",
        "    logits = logits / temperature\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=0).numpy()\n",
        "    return np.random.choice(len(probs), p=probs)\n",
        "\n",
        "def generate_smiles(model, temperature=0.9):\n",
        "    model.eval()\n",
        "    idx = token2idx[START_TOKEN]\n",
        "    seq = [idx]\n",
        "    hidden = None\n",
        "    inp = torch.tensor([[idx]], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(MAX_SEQ_LEN):\n",
        "            logits, hidden = model(inp, hidden)\n",
        "            logits = logits[0, -1].cpu().numpy()\n",
        "            next_idx = sample_next_token(logits, temperature)\n",
        "            seq.append(next_idx)\n",
        "\n",
        "            if next_idx == token2idx[END_TOKEN]:\n",
        "                break\n",
        "\n",
        "            inp = torch.tensor([[next_idx]], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    return decode(seq, idx2token)\n",
        "\n",
        "print(\"Example Generated SMILES:\")\n",
        "for _ in range(10):\n",
        "    print(generate_smiles(model))"
      ]
    }
  ]
}